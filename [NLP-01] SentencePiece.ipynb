{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "250ea103",
   "metadata": {},
   "source": [
    "### 목차\n",
    "***\n",
    "1. 데이터 준비 및 확인_[네이버 영화리뷰](https://github.com/e9t/nsmc)\n",
    "2. 데이터 전처리\n",
    "\t1. 중복 및  결측치 처리\n",
    "\t2. 문장 길이 확인 (최대, 최소 길이 설정)\n",
    "\t3. 노이즈 데이터 확인 및 제거 (길이 1)\n",
    "\t4. 데이터 분포 확인\n",
    "3. **SentencePiece** 모델 학습 : **model_type=unigram**\n",
    "4. Tokenizer 함수 생성\n",
    "5. 데이터 로더 구성\n",
    "6. 모델 구성 및 validation set 구성\n",
    "7. 모델 훈련\n",
    "8. 모델 평가\n",
    "9. 성능 비교\n",
    "\t1. SentencePiece 모델의 **model_type=bpe** 변경\n",
    "\t\t1. SentencePiece 모델학습\n",
    "\t\t2. Tokenizer 함수 생성\n",
    "\t\t3. 데이터 로더 구성\n",
    "\t\t4. 모델 및 validation set 구성\n",
    "\t\t5. 모델 훈련\n",
    "\t\t6. 모델 평가\n",
    "\t2. **KoNLPy** 형태소 분석기를 사용하여 모델 학습\n",
    "\t\t1. 데이터 로더 구성\n",
    "\t\t2. 모델 구성을 위한 데이터 가공\n",
    "\t\t3. 모델 구성 및 validation set 구성\n",
    "\t\t4. 모델 훈련\n",
    "\t\t5. 모델 평가\n",
    "  \n",
    "10. 회고 및 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "5793af98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ca9b76",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4e8a6e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    " \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "de204b0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 3)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b60fa5",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리\n",
    "- 중복 및 결측치 처리\n",
    "- 문장 길이 확인 (최대 최소 평균)\n",
    "- 노이즈 데이터 제거 : 길이1인 문장 확인 등\n",
    "- 문장 분포 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af70f8b0",
   "metadata": {},
   "source": [
    "### 1 중복 및 null 값 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d45f322f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "document    5\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복 및 null 값 처리\n",
    "train_data[train_data['document'].isnull()]\n",
    "test_data[test_data['document'].isnull()]\n",
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1d0dd338",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "train_data = train_data.dropna(how='any')\n",
    "test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "test_data = test_data.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "31264e63",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          0\n",
      "document    0\n",
      "label       0\n",
      "dtype: int64\n",
      "id          0\n",
      "document    0\n",
      "label       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isna().sum())\n",
    "print(test_data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325b1e6c",
   "metadata": {},
   "source": [
    "### 2 문장 길이 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "30026eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195339"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 문장 리스트로 만들어 raw corpus 만들기\n",
    "raw = list(train_data['document'])+list(test_data['document'])\n",
    "type(raw)\n",
    "len(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "76a70a77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 195339\n",
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 146\n",
      "문장의 평균 길이: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/2013385127.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  sentence_length = np.zeros((max_len), dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "print('Data Size:', len(raw))\n",
    "\n",
    "for sen in raw:\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "    \n",
    "print('문장의 최단 길이:', min_len)\n",
    "print('문장의 최장 길이:', max_len)\n",
    "print('문장의 평균 길이:', sum_len // len(raw))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in raw:\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "    \n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title('Sentence Length Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75cc609",
   "metadata": {},
   "source": [
    "### 3 노이즈 데이터 확인 및 제거\n",
    "문장의 최단길이를 확인하기 위해 함수를 이용해 확인한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "52ee6536",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아\n",
      "잼\n",
      "1\n",
      "4\n",
      "굿\n",
      "짱\n",
      "휴\n",
      ".\n",
      "음\n",
      "?\n",
      "ㅎ\n",
      "ㅋ\n",
      "즐\n",
      "♥\n",
      "굳\n",
      "네\n",
      "ㅇ\n",
      "k\n",
      "ㅠ\n",
      "쒯\n",
      "♬\n",
      "토\n",
      "O\n",
      "똥\n",
      "z\n",
      "헐\n",
      "삼\n",
      "꽝\n",
      "!\n",
      "풉\n",
      "ㅅ\n",
      "왜\n",
      "ㄴ\n",
      "쉣\n",
      "봐\n",
      "뿌\n",
      "ㅜ\n",
      "♡\n",
      "ㅁ\n",
      "0\n",
      "ㅉ\n",
      "d\n",
      "흥\n",
      "乃\n",
      "찜\n",
      "귯\n",
      "린\n",
      "시\n",
      "ㅗ\n",
      "a\n",
      "c\n",
      "흠\n",
      "웅\n",
      "ㅣ\n",
      "오\n",
      "9\n",
      "쩜\n",
      "애\n",
      "헝\n",
      "쨩\n",
      "f\n",
      "움\n",
      "ㄳ\n",
      "업\n",
      "헉\n",
      "군\n",
      "b\n",
      ";\n",
      "g\n",
      "올\n",
      "걍\n",
      "허\n",
      "-\n",
      "쀍\n",
      "로\n",
      "ㄹ\n",
      "ㅂ\n",
      "갑\n",
      "즛\n",
      "킥\n",
      "함\n",
      "진\n",
      "ㅡ\n",
      "잠\n",
      "곧\n",
      "ㅍ\n",
      "h\n",
      "·\n",
      "캬\n",
      "ㅆ\n",
      ",\n",
      "풋\n",
      "ㄱ\n",
      "파\n",
      "ㄷ\n",
      "웩\n",
      "꺅\n",
      "욜\n",
      "ㅄ\n",
      "2\n",
      "핡\n"
     ]
    }
   ],
   "source": [
    "def check_sentence_with_length(raw, length):\n",
    "    count = 0\n",
    "    \n",
    "    for sen in raw:\n",
    "        if len(sen) == length:\n",
    "            print(sen)\n",
    "            count += 1\n",
    "            if count > 100: return\n",
    "            \n",
    "check_sentence_with_length(raw, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e11ace3",
   "metadata": {},
   "source": [
    "길이가 1인 문장은 버려도 될 것 같다. 다만 2부터는 굳굳, 최고 등 감성분석에 필요한 단어들이 들어가있으므로 제거하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "f147efb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/4196487287.py:8: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  sentence_length = np.zeros((max_len), dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZt0lEQVR4nO3df5QdZX3H8fdHfgtKwo+mYTe6sURp8FTEK4RKLQWbHyCG47E0LZWVpie1h1pstRi0p1GkCq0VobVoBCRQCqRRJEIqrgFPay2RjSC/As2iYDYkZGGT8MsCgW//mOfiZNnN3s3e/TXP53XOPTvzzHOfeebO3e8888xzZxQRmJlZHl4z1hUwM7PR46BvZpYRB30zs4w46JuZZcRB38wsIw76ZmYZcdA3azJJbZJC0p5NLPMMSd9tYnn3SzohTX9a0r82sexPSrq8WeVZcznoV5yk4yX9UNJ2Sb2S/lvSO5tQ7ock/aAZdWwmSY9Ies9EWqekqyS9IOnp9LpP0uclHVjPExHXRsTsBsu6YLB8EXFkRHx/d+tcWt8Jkrr7lP25iPiT4ZZtI8NBv8IkvR64Gfgn4CCgBfgM8PxY1sv69fcR8TrgUOAsYBbw35L2b+ZKmnn2YROTg361vRkgIq6LiJci4hcR8d2IuKeeQdIfS1onaaukWyW9sbQsJH1Y0npJ2yR9WYVfB74CHCfpGUnbUv59JH1B0s8lPS7pK5L2S8tOkNQt6WOStkjaJOms0rr2k/SPkh5NZyU/KL13Vjpb2SbpJ/VuiaGQ9BpJiyU9LOlJScslHZSW1btj2lPdn5D0qT51W5Y+o3WSzq23biVdA7wB+Hb6LM4trfaM/srblYj4v4i4E3gfcDDFAWCnM6u0Dy5On+NTku6V9FZJi4AzgHNTXb6d8j8i6ROS7gGelbRnP2cn+0q6IZ1p/FjS20rbH5IOL81fJemCdED6D+CwtL5nJB2mPt1Fkt6nojtpm6Tvp+9Pfdkjkj4u6Z6032+QtG8jn5XtHgf9avtf4KUUsOZJmlxeKGk+8Eng/RQtzP8CrutTxnuBdwK/AZwOzImIdcCHgf+JiAMiYlLKeyHFgeYo4HCKM4u/LZX1q8CBKX0h8OVSnb4AvAP4TYqzknOBlyW1ALcAF6T0jwPfkHToED+LjwCnAb8NHAZsBb7cJ8/xwFuAk4C/LQWnJUAb8Cbgd4E/qr8hIj4I/Bw4NX0Wf99AeYOKiKeBDuC3+lk8G3g3xWd9IMV+eTIilgLXUpw1HBARp5be8wfAKcCkiNjRT5nzgX+n+Iz/DfiWpL0GqeOzwDzgsbS+AyLisXIeSW+m+E59lOI7toriALl3KdvpwFxgOsX37EO7Wq8Nj4N+hUXEUxSBJ4CvAT2SVkqakrJ8GPh8RKxLgeBzwFHl1j5wYURsi4ifA7dTBPRXkSRgEfCXEdGbgtbngAWlbC8C50fEixGxCngGeIuk1wB/DJwTERvTWckPI+J5igC7KiJWRcTLEdEBdAInD/Hj+DDwqYjoTuV+GviAdu7u+Ew6G/oJ8BOg3to9HfhcRGyNiG7g0gbXOVB5jXqMIgj39SLwOuAIQGn/bRqkrEsjYkNE/GKA5WsjYkVEvAh8EdiXootpuH4fuCUiOlLZXwD2ozi4l+v2WET0At9mgO+YNYeDfsWlgPChiGgF3krRyv1SWvxG4JJ02r0N6AVE0RKv21yafg44YIBVHQq8FlhbKu87Kb3uyT6tzHp5h1AEmYf7KfeNwO/Vy0zlHg9M3dV2D1DOjaUy1gEvAVNKeQba1sOADaVl5eldafSzG0gLxT7ZSUTcBvwzxZnKFklLVVy/2ZXB6vzK8oh4Geim2O7hOgx4tE/ZG9i975g1gYN+RiLiQeAqiuAPxT/fn0bEpNJrv4j4YSPF9Zl/AvgFcGSprAMjopF/4CeA/wN+rZ9lG4Br+tRx/4i4sIFy+5Yzr085+0bExgbeuwloLc1P67O86beqlXQA8B6KLrdXiYhLI+IdwEyKbp6/HqQug9XxlW1KZ16tFGcaUATi15by/uoQyn2M4oBbL1tpXY187jYCHPQrTNIR6cJpa5qfRtG3e0fK8hXgPElHpuUHSvq9Bot/HGit982mFtzXgIsl/Uoqr0XSnMEKSu+9EvhiuhC4h6TjJO0D/CtwqqQ5KX1fFReFW3dR5F4pX/21Z9rWv6t3XUk6NF3TaMRyis9pcrrG8Of9fBZvarCsXVJxMfwdwLcorjt8vZ8875R0bOpzf5bigPnyMOvyDknvT5/VRylGeNW/J3cDf5g+/7kU10XqHgcOVml4aR/LgVMknZTq+7FUdiMNCxsBDvrV9jRwLLBG0rMU/8T3UfzjERE3AhcB10t6Ki2b12DZtwH3A5slPZHSPgF0AXek8r5HcSGzER8H7gXupOjSuAh4TURsoLjI+Emgh6LF/tfs+ru7iuKso/76NHAJsBL4rqSnKT6LYxus2/kU3R0/S9u0gp2HvX4e+JvUdfTxBsvs69xUryeBq4G1wG+mi6V9vZ7iALuVouvkSeAf0rIrgJmpLt8awvpvouh/3wp8EHh/6oMHOAc4FdhGMTrolXLT2eN1wE/TOnfqEoqIhyiuy/wTxRndqRQXvV8YQt2sieSHqJgNjaQ/AxZExG8PmtlsnHFL32wQkqZKepeKsf5voThTunGs62W2O/zrPLPB7Q18lWIc+TbgeuBfxrJCZrvL3TtmZhlx946ZWUbGdffOIYccEm1tbWNdDTOzCWXt2rVPRES/tyoZ10G/ra2Nzs7Osa6GmdmEIunRgZa5e8fMLCMO+mZmGXHQNzPLiIO+mVlGHPTNzDLSUNCXNEnSCkkPqnhc3HGSDpLUoeJReh31JyCpcKmkrvQItKNL5bSn/OsltY/URpmZWf8abelfAnwnIo6gePrPOmAxsDoiZgCr0zwUd2mckV6LgMsAVDyPdAnFnQ2PAZb0fXyfmZmNrEGDfrpP9rspbtlKRLwQEdsobne7LGVbRvH8UVL61VG4A5gkaSowB+hIj9LbSvH8z7lN3BYzMxtEIy396RT3Mf+6pLskXS5pf2BK6bmcm/nlY+da2PnRbN0pbaD0nUhaJKlTUmdPT8/QtsbMzHapkV/k7gkcDXwkItZIuoRfduUAEBEhqSl3bouIpcBSgFqtVqm7wbUtvuWV6UcuPGUMa2JmuWqkpd8NdEfEmjS/guIg8HjqtiH93ZKWb2TnZ4i2prSB0s3MbJQMGvQjYjOwIT08AuAk4AGKR8/VR+C0UzxujZR+ZhrFMwvYnrqBbgVmp+eMTgZmpzQzMxsljd5w7SPAtekh2D8FzqI4YCyXtJDiOZ2np7yrgJMpnpX6XMpLRPRK+izFM1ABzo+I3qZshZmZNWRcP0SlVqtFle6yWe7TL3P/vpk1k6S1EVHrb5l/kWtmlhEHfTOzjDjom5llxEHfzCwj4/pxiVUw0MVbM7Ox4Ja+mVlGHPTNzDLioG9mlhEHfTOzjDjom5llxEHfzCwjHrI5Dvg++2Y2WtzSNzPLiIO+mVlGHPTNzDLioG9mlhEHfTOzjDjom5llxEHfzCwjDvpmZhnxj7PGGf9Qy8xGklv6ZmYZcdA3M8uIg76ZWUYc9M3MMuKgb2aWkYaCvqRHJN0r6W5JnSntIEkdktanv5NTuiRdKqlL0j2Sji6V057yr5fUPjKbZGZmAxlKS/93IuKoiKil+cXA6oiYAaxO8wDzgBnptQi4DIqDBLAEOBY4BlhSP1CYmdnoGE73znxgWZpeBpxWSr86CncAkyRNBeYAHRHRGxFbgQ5g7jDWb2ZmQ9Toj7MC+K6kAL4aEUuBKRGxKS3fDExJ0y3AhtJ7u1PaQOk7kbSI4gyBN7zhDQ1Wr5r8Qy0za7ZGg/7xEbFR0q8AHZIeLC+MiEgHhGFLB5SlALVarSllmplZoaGgHxEb098tkm6k6JN/XNLUiNiUum+2pOwbgWmlt7emtI3ACX3Svz+s2mfErX4za4ZB+/Ql7S/pdfVpYDZwH7ASqI/AaQduStMrgTPTKJ5ZwPbUDXQrMFvS5HQBd3ZKMzOzUdJIS38KcKOkev5/i4jvSLoTWC5pIfAocHrKvwo4GegCngPOAoiIXkmfBe5M+c6PiN6mbYmZmQ1q0KAfET8F3tZP+pPASf2kB3D2AGVdCVw59GqamVkz+Be5ZmYZ8f30JyBf1DWz3eWWvplZRhz0zcwy4qBvZpYRB30zs4w46JuZZcSjdyY4j+Qxs6FwS9/MLCMO+mZmGXH3ToW4q8fMBuOWvplZRtzSHwHlFreZ2XjioF9RfQ887u4xM3D3jplZVhz0zcwy4qBvZpYRB30zs4w46JuZZcSjdzLhH26ZGbilb2aWFQd9M7OMOOibmWXEQd/MLCO+kJshX9Q1y1fDLX1Je0i6S9LNaX66pDWSuiTdIGnvlL5Pmu9Ky9tKZZyX0h+SNKfpW2NmZrs0lO6dc4B1pfmLgIsj4nBgK7AwpS8Etqb0i1M+JM0EFgBHAnOBf5G0x/Cqb8PVtviWV15mVn0NBX1JrcApwOVpXsCJwIqUZRlwWpqen+ZJy09K+ecD10fE8xHxM6ALOKYJ22BmZg1qtKX/JeBc4OU0fzCwLSJ2pPluoCVNtwAbANLy7Sn/K+n9vOcVkhZJ6pTU2dPT0/iWmJnZoAa9kCvpvcCWiFgr6YSRrlBELAWWAtRqtRjp9dkv+QKvWfU1MnrnXcD7JJ0M7Au8HrgEmCRpz9SabwU2pvwbgWlAt6Q9gQOBJ0vpdeX3mJnZKBi0eycizouI1ohoo7gQe1tEnAHcDnwgZWsHbkrTK9M8afltEREpfUEa3TMdmAH8qGlbYmZmgxrOOP1PANdLugC4C7gipV8BXCOpC+ilOFAQEfdLWg48AOwAzo6Il4axfjMzGyIVjfDxqVarRWdn51hXY8iqNvzR/ftmE4uktRFR62+Zb8NgZpYR34bBBuVRPWbV4Za+mVlG3NK3IXGr32xic0vfzCwjDvpmZhlx947tNnf1mE08bumbmWXEQd/MLCMO+mZmGXGfvjXFQLeecF+/2fjilr6ZWUYc9M3MMuKgb2aWEQd9M7OM+EJuk1TtHvpmVk1u6ZuZZcQtfRtRHsppNr64pW9mlhEHfTOzjDjom5llxEHfzCwjDvpmZhlx0Dczy4iDvplZRhz0zcwyMmjQl7SvpB9J+omk+yV9JqVPl7RGUpekGyTtndL3SfNdaXlbqazzUvpDkuaM2FaZmVm/GvlF7vPAiRHxjKS9gB9I+g/gr4CLI+J6SV8BFgKXpb9bI+JwSQuAi4DflzQTWAAcCRwGfE/SmyPipRHYLhvn/FB1s7ExaEs/Cs+k2b3SK4ATgRUpfRlwWpqen+ZJy0+SpJR+fUQ8HxE/A7qAY5qxEWZm1piG+vQl7SHpbmAL0AE8DGyLiB0pSzfQkqZbgA0Aafl24OByej/vKa9rkaROSZ09PT1D3iAzMxtYQ0E/Il6KiKOAVorW+REjVaGIWBoRtYioHXrooSO1GjOzLA1p9E5EbANuB44DJkmqXxNoBTam6Y3ANIC0/EDgyXJ6P+8xM7NR0MjonUMlTUrT+wG/C6yjCP4fSNnagZvS9Mo0T1p+W0RESl+QRvdMB2YAP2rSdpiZWQMaGb0zFVgmaQ+Kg8TyiLhZ0gPA9ZIuAO4Crkj5rwCukdQF9FKM2CEi7pe0HHgA2AGc7ZE7ZmajS0UjfHyq1WrR2dk51tVoiB+X2ByNDN/0cE+zXZO0NiJq/S3zL3LNzDLioG9mlhE/I9cmBHefmTWHg76NKw7uZiPL3TtmZhlx0Dczy4iDvplZRtynb5Xncf1mv+Sgb1npe6HYBwHLjbt3zMwy4qBvZpYRB30zs4y4T98mNP+Yy2xoHPSHwQHHzCYad++YmWXEQd/MLCMO+mZmGXHQNzPLiC/kDpEv3prZROaWvplZRtzSb4Bb99Xlm7FZbtzSNzPLiIO+mVlGHPTNzDLioG9mlpFBg76kaZJul/SApPslnZPSD5LUIWl9+js5pUvSpZK6JN0j6ehSWe0p/3pJ7SO3WWZm1p9GWvo7gI9FxExgFnC2pJnAYmB1RMwAVqd5gHnAjPRaBFwGxUECWAIcCxwDLKkfKMzMbHQMGvQjYlNE/DhNPw2sA1qA+cCylG0ZcFqang9cHYU7gEmSpgJzgI6I6I2IrUAHMLeZG2NmZrs2pD59SW3A24E1wJSI2JQWbQampOkWYEPpbd0pbaB0MzMbJQ0HfUkHAN8APhoRT5WXRUQA0YwKSVokqVNSZ09PTzOKNDOzpKFf5EraiyLgXxsR30zJj0uaGhGbUvfNlpS+EZhWentrStsInNAn/ft91xURS4GlALVarSkHkt3hX+GaWRU1MnpHwBXAuoj4YmnRSqA+AqcduKmUfmYaxTML2J66gW4FZkuanC7gzk5pZmY2Shpp6b8L+CBwr6S7U9ongQuB5ZIWAo8Cp6dlq4CTgS7gOeAsgIjolfRZ4M6U7/yI6G3GRpiZWWMGDfoR8QNAAyw+qZ/8AZw9QFlXAlcOpYJmZtY8/kWumVlGHPTNzDLioG9mlhEHfTOzjDjom5llxEHfzCwjfkauWeLn5VoO3NI3M8uIg76ZWUYc9M3MMuI+/RLfWdPMqs4tfTOzjDjom5llxEHfzCwjDvpmZhlx0Dczy4iDvplZRhz0zcwykv04fY/NN7OcZB/0zfrjm69ZVbl7x8wsIw76ZmYZcdA3M8uIg76ZWUYc9M3MMuKgb2aWkUGDvqQrJW2RdF8p7SBJHZLWp7+TU7okXSqpS9I9ko4uvac95V8vqX1kNses+doW3/LKy2yia6SlfxUwt0/aYmB1RMwAVqd5gHnAjPRaBFwGxUECWAIcCxwDLKkfKMzMbPQMGvQj4j+B3j7J84FlaXoZcFop/eoo3AFMkjQVmAN0RERvRGwFOnj1gcTMzEbY7vbpT4mITWl6MzAlTbcAG0r5ulPaQOmvImmRpE5JnT09PbtZPTMz68+wb8MQESEpmlGZVN5SYClArVZrWrlmzeDbM9hEt7st/cdTtw3p75aUvhGYVsrXmtIGSjczs1G0u0F/JVAfgdMO3FRKPzON4pkFbE/dQLcCsyVNThdwZ6c0MzMbRYN270i6DjgBOERSN8UonAuB5ZIWAo8Cp6fsq4CTgS7gOeAsgIjolfRZ4M6U7/yI6HtxeNR46J01g7t6bCJSxPjtNq/VatHZ2dn0ch30bST5AGBjTdLaiKj1t8y/yDUzy4gfomLWZAOdSfoMwMYDB32zUeJrADYeuHvHzCwjDvpmZhlx947ZGHC/v40VB32zcaSR4cQ+MNhwuHvHzCwjbumbTTADjQLy6CBrRDZB37/CNTPLKOibVdFAjRlfG7CBOOibZWpXBwYfEKrLQd/MXqWRIaW+hjAxOeibWcOG2p3kg8H446BvZqPCB4bxwUHfzEZMIxeUh3owcLfS8Djom9m4NBIHDHPQN7OKa+TMIKeDh4O+mVXOcH6/sDvrmEgHBwd9M7MGNWv00lieWWTzYHTfhsHMJpLhHAD8YHQzMwMc9M3MsuKgb2aWEQd9M7OMOOibmWVk1IO+pLmSHpLUJWnxaK/fzCxnoxr0Je0BfBmYB8wE/kDSzNGsg5lZzka7pX8M0BURP42IF4DrgfmjXAczs2yN9i9yW4ANpflu4NhyBkmLgEVp9hlJDw1znYcATwyzjInG25wHb3OF6SJg97f3jQMtGHe3YYiIpcDSZpUnqXOgX6ZVlbc5D97m6huJ7R3t7p2NwLTSfGtKMzOzUTDaQf9OYIak6ZL2BhYAK0e5DmZm2RrV7p2I2CHpz4FbgT2AKyPi/hFebdO6iiYQb3MevM3V1/TtHdd32TQzs+byL3LNzDLioG9mlpFKB/2q3/JB0jRJt0t6QNL9ks5J6QdJ6pC0Pv2dPNZ1bTZJe0i6S9LNaX66pDVpX9+QBgpUhqRJklZIelDSOknHVX0/S/rL9L2+T9J1kvat2n6WdKWkLZLuK6X1u19VuDRt+z2Sjt6ddVY26Gdyy4cdwMciYiYwCzg7beNiYHVEzABWp/mqOQdYV5q/CLg4Ig4HtgILx6RWI+cS4DsRcQTwNoptr+x+ltQC/AVQi4i3Ugz8WED19vNVwNw+aQPt13nAjPRaBFy2OyusbNAng1s+RMSmiPhxmn6aIhC0UGznspRtGXDamFRwhEhqBU4BLk/zAk4EVqQsldpmSQcC7wauAIiIFyJiGxXfzxSjC/eTtCfwWmATFdvPEfGfQG+f5IH263zg6ijcAUySNHWo66xy0O/vlg8tY1SXESepDXg7sAaYEhGb0qLNwJSxqtcI+RJwLvBymj8Y2BYRO9J81fb1dKAH+Hrq0rpc0v5UeD9HxEbgC8DPKYL9dmAt1d7PdQPt16bEtCoH/WxIOgD4BvDRiHiqvCyKMbmVGZcr6b3AlohYO9Z1GUV7AkcDl0XE24Fn6dOVU8H9PJmiZTsdOAzYn1d3g1TeSOzXKgf9LG75IGkvioB/bUR8MyU/Xj/tS3+3jFX9RsC7gPdJeoSiy+5Eiv7uSakbAKq3r7uB7ohYk+ZXUBwEqryf3wP8LCJ6IuJF4JsU+77K+7luoP3alJhW5aBf+Vs+pL7sK4B1EfHF0qKVQHuabgduGu26jZSIOC8iWiOijWKf3hYRZwC3Ax9I2aq2zZuBDZLekpJOAh6gwvuZoltnlqTXpu95fZsru59LBtqvK4Ez0yieWcD2UjdQ4yKisi/gZOB/gYeBT411fUZg+46nOPW7B7g7vU6m6ONeDawHvgccNNZ1HaHtPwG4OU2/CfgR0AX8O7DPWNevydt6FNCZ9vW3gMlV38/AZ4AHgfuAa4B9qrafgesorlm8SHFGt3Cg/QqIYkTiw8C9FCObhrxO34bBzCwjVe7eMTOzPhz0zcwy4qBvZpYRB30zs4w46JuZZcRB38wsIw76ZmYZ+X+3BCww+OU9vQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_len = 100\n",
    "min_len = 2\n",
    "\n",
    "# 길이 조건에 맞는 문장만 선택한다.\n",
    "filtered_corpus = [s for s in raw if (len(s) <= max_len) & (len(s) >= min_len)]\n",
    "\n",
    "# 분포도를 다시 그려본다.\n",
    "sentence_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in filtered_corpus:\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "    \n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title('Sentence Length Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bb316d",
   "metadata": {},
   "source": [
    "## 3. SentencePiece 모델 학습\n",
    "토큰화를 위한 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0d6a996c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 336404 Mar 23 07:14 korean_spm.model\r\n",
      "-rw-r--r-- 1 root root 104063 Mar 23 07:14 korean_spm.vocab\r\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import os\n",
    "temp_file = os.getenv('HOME') + '/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp'\n",
    "\n",
    "vocab_size = 6000\n",
    "\n",
    "with open(temp_file, 'w') as f:\n",
    "    for row in filtered_corpus: # 이전 스텝에서 정제했던 corpus 활용\n",
    "        f.write(str(row) + '\\n')\n",
    "        \n",
    "spm.SentencePieceTrainer.Train('--input={} --model_prefix=korean_spm --vocab_size={}'.format(temp_file, vocab_size))\n",
    "\n",
    "# 위 Train에서 --model_type = 'unigram'이 디폴트 적용되어 있다.\n",
    "# --model_type = 'bpe' 로 옵션을 주어 변경할 수 있다.\n",
    "\n",
    "!ls -l korean_spm*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec7a8d2",
   "metadata": {},
   "source": [
    "#### 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9f54328d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = spm.SentencePieceProcessor()\n",
    "s.Load('korean_spm.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "14a863b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1682, 9, 321, 15, 1445, 9, 104, 17, 4]\n",
      "['▁아버지', '가', '방', '에', '들어', '가', '신', '다', '.']\n",
      "아버지가방에들어가신다.\n"
     ]
    }
   ],
   "source": [
    "# SentencePiece를 활용한 sentence -> encoding\n",
    "tokensIDs = s.EncodeAsIds('아버지가방에들어가신다.')\n",
    "print(tokensIDs) # 아이디로 토크나이즈\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoded pieces\n",
    "print(s.SampleEncodeAsPieces('아버지가방에들어가신다.', 1, 0.0))\n",
    "# 문자열에 대해 토크나이즈\n",
    "\n",
    "# SentencePiece를 활용한 encoding -> sentence 복원\n",
    "print(s.DecodeIds(tokensIDs))\n",
    "# 아이디를 통해 디코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282bee2c",
   "metadata": {},
   "source": [
    "## 4. Tokenizer 함수 생성\n",
    "위에서 훈련시킨 SentencePiece를 활용하여 위 함수와 유사한 기능을 하는 sp_tokenize() 함수를 정의한다.  \n",
    "하지만 SentencePiece가 동작하는 방식이 단순 토큰화와는 달라 완전히 동일하게는 정의하기 어렵다.  \n",
    "따라서 아래 조건을 만족하는 함수를 정의한다.\n",
    ">1) 매개변수로 토큰화된 문장의 list를 전달하는 대신 **온전한 문장**의 list를 전달한다.  \n",
    ">2) **생성된 vocab 파일**을 읽어와 { <word\\> : <idx\\> } 형태를 가지는 word_index 사전과 { <idx\\> : <word\\> } 형태를 가지는 index_word 사전을 생성하고 함께 반환한다.  \n",
    ">3) 리턴값인 tensor는 앞의 함수와 동일하게 토큰화한 후 Encoding 된 문장이다. 바로 학습에 사용할 수 있게 padding도 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "88933b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_tokenize(s, corpus):\n",
    "    \n",
    "    tensor = []\n",
    "    \n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen)) # 아이디로 문장 토큰화된 값 추가\n",
    "        \n",
    "    with open(\"./korean_spm.vocab\", 'r') as f:\n",
    "        vocab = f.readlines()\n",
    "        \n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "    \n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "        \n",
    "        word_index.update({word:idx})\n",
    "        index_word.update({idx:word})\n",
    "        \n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=100)\n",
    "    \n",
    "    return tensor, word_index, index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "7f0ebaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sp_tokenize(s, corpus) 사용예제\n",
    "\n",
    "my_corpus = ['나는 밥을 먹었습니다.', '그러나 여전히 ㅠㅠ 배가 고픕니다...']\n",
    "\n",
    "tensor, word_index, index_word = sp_tokenize(s, my_corpus)\n",
    "#print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "fb41fc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_index\n",
    "#index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fc801c",
   "metadata": {},
   "source": [
    "## 5. 데이터 로더 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d000c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_words = 8000\n",
    "\n",
    "def load_data(train_data, test_data):\n",
    "    \n",
    "    # 토큰화 및 불용어 제거\n",
    "    X_train, word_index, index_word = sp_tokenize(s, list(train_data['document']))\n",
    "    \n",
    "    X_test, _, _ = sp_tokenize(s, list(test_data['document']))\n",
    "    \n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_index, index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e82cfc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, word_index, index_word = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5c2e03",
   "metadata": {},
   "source": [
    "sp_tokenize에서 padding한 값을 리턴하니까 따로 padding을 수행하진 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fedbdb",
   "metadata": {},
   "source": [
    "## 6. 모델 구성 및 validation set 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "f538abd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, None, 16)          96000     \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 96,881\n",
      "Trainable params: 96,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# sp_tokenize를 이용한 모델\n",
    "vocab_size = 6000\n",
    "word_vector_dim = 16\n",
    "\n",
    "model_sp = tf.keras.Sequential()\n",
    "model_sp.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model_sp.add(tf.keras.layers.LSTM(8))\n",
    "model_sp.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model_sp.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_sp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "6d2d8bba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116182, 100)\n",
      "(116182,)\n",
      "(30000, 100)\n"
     ]
    }
   ],
   "source": [
    "# validation set 구성\n",
    "x_val = X_train[:30000]\n",
    "y_val = y_train[:30000]\n",
    "\n",
    "# 나머지\n",
    "partial_x_train = X_train[30000:]\n",
    "partial_y_train = y_train[30000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7743e51",
   "metadata": {},
   "source": [
    "## 7. 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "c620c2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "454/454 [==============================] - 5s 8ms/step - loss: 0.6932 - accuracy: 0.5006 - val_loss: 0.6931 - val_accuracy: 0.5024\n",
      "Epoch 2/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.6931 - accuracy: 0.5018 - val_loss: 0.6931 - val_accuracy: 0.5024\n",
      "Epoch 3/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.6639 - accuracy: 0.5827 - val_loss: 0.6354 - val_accuracy: 0.6715\n",
      "Epoch 4/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.6404 - accuracy: 0.6424 - val_loss: 0.6579 - val_accuracy: 0.5878\n",
      "Epoch 5/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.6522 - accuracy: 0.6008 - val_loss: 0.6506 - val_accuracy: 0.6075\n",
      "Epoch 6/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.6473 - accuracy: 0.6146 - val_loss: 0.6482 - val_accuracy: 0.6147\n",
      "Epoch 7/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.6277 - accuracy: 0.6759 - val_loss: 0.6251 - val_accuracy: 0.6746\n",
      "Epoch 8/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.6232 - accuracy: 0.6746 - val_loss: 0.6223 - val_accuracy: 0.6850\n",
      "Epoch 9/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.6204 - accuracy: 0.6812 - val_loss: 0.6196 - val_accuracy: 0.6784\n",
      "Epoch 10/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.6194 - accuracy: 0.6823 - val_loss: 0.6201 - val_accuracy: 0.6850\n",
      "Epoch 11/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.6251 - accuracy: 0.6631 - val_loss: 0.6279 - val_accuracy: 0.6479\n",
      "Epoch 12/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.6330 - accuracy: 0.6355 - val_loss: 0.6328 - val_accuracy: 0.6331\n",
      "Epoch 13/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.6295 - accuracy: 0.6432 - val_loss: 0.6246 - val_accuracy: 0.6528\n",
      "Epoch 14/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.6257 - accuracy: 0.6516 - val_loss: 0.6236 - val_accuracy: 0.6553\n",
      "Epoch 15/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.6254 - accuracy: 0.6505 - val_loss: 0.6291 - val_accuracy: 0.6384\n",
      "Epoch 16/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.6256 - accuracy: 0.6456 - val_loss: 0.6207 - val_accuracy: 0.6550\n",
      "Epoch 17/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.6229 - accuracy: 0.6523 - val_loss: 0.6167 - val_accuracy: 0.6737\n",
      "Epoch 18/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.6160 - accuracy: 0.6722 - val_loss: 0.6175 - val_accuracy: 0.6703\n",
      "Epoch 19/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.6156 - accuracy: 0.6713 - val_loss: 0.6161 - val_accuracy: 0.6717\n",
      "Epoch 20/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.6144 - accuracy: 0.6721 - val_loss: 0.6158 - val_accuracy: 0.6715\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "model_sp.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "history = model_sp.fit(partial_x_train,\n",
    "                      partial_y_train,\n",
    "                      epochs=epochs,\n",
    "                      batch_size = 256,\n",
    "                      validation_data=(x_val, y_val),\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ca5a68",
   "metadata": {},
   "source": [
    "## 8. 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "d1b47848",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 4s - loss: 0.6198 - accuracy: 0.6640\n",
      "-----<sp_tokenizer를 사용한 모델>-----: \n",
      " [0.61982262134552, 0.6640356183052063]\n"
     ]
    }
   ],
   "source": [
    "results_sp = model_sp.evaluate(X_test, y_test, verbose=2)\n",
    "print('-----<sp_tokenizer를 사용한 모델>-----: \\n', results_sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3453fb17",
   "metadata": {},
   "source": [
    "초반에 모델 돌렸을 때 정확도가 83 정도 나왔었는데, 아래 bpe 돌리고 난 뒤 다시 돌려보니 그 정도의 성능은 안나온다.. \n",
    "\n",
    "맨 처음엔 SentencePiece 모델 학습할 때부터 vocab_size를 8000으로 두고 시작했는데, 6000정도로 사이즈를 줄이니 성능이 더 좋게 나오는 것 같다. \n",
    "\n",
    "따라서 아래에 성능 비교할 때 vocab_size를 6000으로 고정한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c4201f",
   "metadata": {},
   "source": [
    "# 9. 성능 비교\n",
    "- SentecePiece 모델의 model_type, vocab_size 등을 변경해가며 성능개선 여부 확인하기\n",
    "- KoNLPY 형태소 분석기를 사용한 모델과 성능 비교\n",
    "\n",
    "## 1 SentencePiece 모델의 model_type 변경\n",
    "***\n",
    "model_type = 'bpe'로 변경\n",
    "### 1-1. SentencePiece 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "82a499d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/aiffel/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp --model_prefix=korean_spm --vocab_size=6000 --model_type=bpe\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /aiffel/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp\n",
      "  input_format: \n",
      "  model_prefix: korean_spm\n",
      "  model_type: BPE\n",
      "  vocab_size: 6000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: /aiffel/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 183597 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=5754961\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9501% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1729\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999501\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 183597 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 183597\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 369137\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=84109 min_freq=89\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12157 size=20 all=112592 active=10697 piece=▁너무\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9491 size=40 all=116465 active=14570 piece=▁안\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6625 size=60 all=120377 active=18482 piece=▁모\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5473 size=80 all=125091 active=23196 piece=배우\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4502 size=100 all=127908 active=26013 piece=▁느\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=4481 min_freq=75\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3907 size=120 all=131911 active=10364 piece=▁것\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3436 size=140 all=134076 active=12529 piece=▁애\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3091 size=160 all=136474 active=14927 piece=보고\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2773 size=180 all=138982 active=17435 piece=!!!\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2606 size=200 all=141434 active=19887 piece=▁바\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=2596 min_freq=66\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2328 size=220 all=144092 active=9611 piece=적이\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2179 size=240 all=146623 active=12142 piece=▁이렇게\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2008 size=260 all=149059 active=14578 piece=▁모르\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1894 size=280 all=151407 active=16926 piece=에게\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1787 size=300 all=153866 active=19384 piece=이나\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1785 min_freq=59\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1670 size=320 all=156355 active=9751 piece=만에\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1570 size=340 all=158234 active=11630 piece=진짜\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1452 size=360 all=160691 active=14087 piece=▁그런\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1411 size=380 all=162723 active=16119 piece=아서\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1362 size=400 all=164233 active=17629 piece=▁보기\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1361 min_freq=54\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1301 size=420 all=166362 active=10303 piece=하면\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1231 size=440 all=168173 active=12114 piece=▁원작\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1187 size=460 all=169709 active=13650 piece=더라\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1127 size=480 all=171440 active=15381 piece=▁전개\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1085 size=500 all=173468 active=17409 piece=▁추천\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1083 min_freq=50\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1039 size=520 all=174862 active=10017 piece=▁뭔가\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=997 size=540 all=175873 active=11028 piece=▁잔잔\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=964 size=560 all=177963 active=13118 piece=▁대단\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=935 size=580 all=180130 active=15285 piece=▁갈\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=916 size=600 all=181882 active=17037 piece=던데\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=914 min_freq=47\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=887 size=620 all=184324 active=11386 piece=▁아쉽\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=857 size=640 all=185969 active=13031 piece=해요\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=831 size=660 all=188207 active=15269 piece=▁아름다운\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=800 size=680 all=189806 active=16868 piece=▁악\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=780 size=700 all=191834 active=18896 piece=▁천\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=779 min_freq=43\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=755 size=720 all=193188 active=10876 piece=이네\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=731 size=740 all=194495 active=12183 piece=만큼\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=714 size=760 all=195933 active=13621 piece=▁괜찮은\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=697 size=780 all=197556 active=15244 piece=▁영화입니다\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=680 size=800 all=198692 active=16380 piece=이야\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=680 min_freq=41\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=665 size=820 all=200883 active=11897 piece=▁산\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=653 size=840 all=201898 active=12912 piece=▁감독의\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=638 size=860 all=202855 active=13869 piece=▁되는\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=627 size=880 all=204358 active=15372 piece=▁없음\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=611 size=900 all=205329 active=16343 piece=▁깊\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=610 min_freq=39\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=596 size=920 all=206512 active=11420 piece=▁답답\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=581 size=940 all=207591 active=12499 piece=▁깨\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=572 size=960 all=209182 active=14090 piece=▁엔딩\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=560 size=980 all=210349 active=15257 piece=▁함께\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=544 size=1000 all=212165 active=17073 piece=▁작가\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=543 min_freq=38\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=528 size=1020 all=213409 active=11781 piece=▁러\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=516 size=1040 all=214331 active=12703 piece=▁있었\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=504 size=1060 all=215548 active=13920 piece=▁이쁘\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=492 size=1080 all=217072 active=15444 piece=▁엉성\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=480 size=1100 all=218493 active=16865 piece=▁패\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=480 min_freq=36\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=469 size=1120 all=219707 active=12078 piece=▁뛰어\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=462 size=1140 all=220668 active=13039 piece=▁있고\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=452 size=1160 all=221630 active=14001 piece=▁않는다\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=443 size=1180 all=222838 active=15209 piece=▁엄마\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=433 size=1200 all=223928 active=16299 piece=▁갈수록\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=433 min_freq=35\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=426 size=1220 all=225128 active=12383 piece=▁감동적인\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=418 size=1240 all=226340 active=13594 piece=▁결말이\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=412 size=1260 all=227442 active=14696 piece=▁b\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=404 size=1280 all=228546 active=15800 piece=타지\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=397 size=1300 all=230214 active=17468 piece=▁취\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=397 min_freq=33\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=390 size=1320 all=231157 active=12420 piece=▁영화임\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=382 size=1340 all=232298 active=13561 piece=▁ᅳ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=375 size=1360 all=233404 active=14667 piece=▁슬픈\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=369 size=1380 all=234507 active=15770 piece=▁볼만한\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=360 size=1400 all=235749 active=17012 piece=▁전부\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=360 min_freq=32\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=355 size=1420 all=236580 active=12583 piece=▁중간에\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=347 size=1440 all=238039 active=14042 piece=버지\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=342 size=1460 all=239175 active=15178 piece=을수\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=337 size=1480 all=240448 active=16451 piece=▁존재\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=332 size=1500 all=241339 active=17342 piece=▁소설\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=332 min_freq=31\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=327 size=1520 all=242308 active=12983 piece=▁봐라\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=320 size=1540 all=243236 active=13911 piece=▁TV\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=315 size=1560 all=244192 active=14867 piece=▁판타지\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=310 size=1580 all=245164 active=15839 piece=봐서\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=307 size=1600 all=246356 active=17031 piece=다는게\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=307 min_freq=30\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=303 size=1620 all=247413 active=13295 piece=▁정도로\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=299 size=1640 all=248318 active=14200 piece=▁식상\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=294 size=1660 all=249425 active=15307 piece=▁누구\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=288 size=1680 all=250623 active=16505 piece=거나\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=284 size=1700 all=251445 active=17327 piece=▁묘\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=284 min_freq=29\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=281 size=1720 all=252440 active=13546 piece=▁어쩔\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=278 size=1740 all=253409 active=14515 piece=▁평점에\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=274 size=1760 all=254539 active=15645 piece=애니\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=270 size=1780 all=255835 active=16941 piece=▁놈\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=267 size=1800 all=256499 active=17605 piece=났다\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=267 min_freq=28\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=263 size=1820 all=257397 active=13665 piece=재밌게\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=260 size=1840 all=258181 active=14448 piece=▁엉망\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=257 size=1860 all=259066 active=15333 piece=▁참고\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=254 size=1880 all=260029 active=16296 piece=▁댓글\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=251 size=1900 all=260630 active=16897 piece=▁없네요\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=251 min_freq=27\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=247 size=1920 all=261355 active=13749 piece=▁찌\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=244 size=1940 all=262038 active=14432 piece=고싶\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=241 size=1960 all=262976 active=15370 piece=▁죽음\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=237 size=1980 all=263910 active=16304 piece=▁북\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=234 size=2000 all=264501 active=16895 piece=줄알\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=234 min_freq=26\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=231 size=2020 all=265722 active=14375 piece=▁이연\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=228 size=2040 all=266504 active=15157 piece=▁그랬\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=226 size=2060 all=267615 active=16268 piece=▁감동적\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=223 size=2080 all=268386 active=17039 piece=되어\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=220 size=2100 all=269306 active=17959 piece=같은데\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=220 min_freq=26\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=218 size=2120 all=270165 active=14271 piece=였어요\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=216 size=2140 all=271176 active=15282 piece=▁이상한\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=213 size=2160 all=271766 active=15872 piece=스를\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=211 size=2180 all=272849 active=16955 piece=▁부족한\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=208 size=2200 all=273858 active=17964 piece=▁팔\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=208 min_freq=25\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=207 size=2220 all=274696 active=14468 piece=▁보지마세요\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=204 size=2240 all=275563 active=15335 piece=분에\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=202 size=2260 all=276151 active=15923 piece=었나\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=200 size=2280 all=276942 active=16714 piece=도없고\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=198 size=2300 all=278238 active=18010 piece=▁나를\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=198 min_freq=24\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=196 size=2320 all=278686 active=14355 piece=소재\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=195 size=2340 all=279498 active=15167 piece=▁예쁜\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=194 size=2360 all=280252 active=15921 piece=▁오락\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=192 size=2380 all=281193 active=16862 piece=았어요\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=190 size=2400 all=281817 active=17486 piece=구려\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=190 min_freq=23\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=188 size=2420 all=282636 active=14866 piece=니아\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=187 size=2440 all=283547 active=15777 piece=퀄리티\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=185 size=2460 all=284339 active=16569 piece=?)\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=183 size=2480 all=285423 active=17653 piece=▁무협\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=182 size=2500 all=286123 active=18353 piece=▁이연걸\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=182 min_freq=23\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=181 size=2520 all=286864 active=15022 piece=▁음악이\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=179 size=2540 all=287382 active=15540 piece=▁오히려\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=177 size=2560 all=288206 active=16364 piece=▁순수한\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=175 size=2580 all=288877 active=17035 piece=▁딴\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=174 size=2600 all=289496 active=17654 piece=으론\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=174 min_freq=22\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=173 size=2620 all=290175 active=15102 piece=원이\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=172 size=2640 all=290967 active=15894 piece=▁시걸\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=171 size=2660 all=291335 active=16262 piece=▁오그라\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=169 size=2680 all=292112 active=17039 piece=▁그립\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=167 size=2700 all=292648 active=17575 piece=▁꾸\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=167 min_freq=22\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=166 size=2720 all=293399 active=15353 piece=▁마치\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=164 size=2740 all=294288 active=16242 piece=히는\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=163 size=2760 all=294935 active=16889 piece=▁언제나\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=161 size=2780 all=295823 active=17777 piece=▁일상\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=160 size=2800 all=296528 active=18482 piece=▁태어\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=160 min_freq=21\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=159 size=2820 all=297353 active=15643 piece=▁시사회\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=157 size=2840 all=297786 active=16076 piece=▁밝\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=156 size=2860 all=298567 active=16857 piece=▁이쁜\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=154 size=2880 all=299403 active=17693 piece=▁00\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=153 size=2900 all=299923 active=18213 piece=▁밋밋\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=153 min_freq=21\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=152 size=2920 all=300611 active=15664 piece=▁아직까지\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=151 size=2940 all=301378 active=16431 piece=▁이제야\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=150 size=2960 all=302130 active=17183 piece=▁베스트\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=148 size=2980 all=302741 active=17794 piece=▁침\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=147 size=3000 all=303428 active=18481 piece=안에\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=147 min_freq=21\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=146 size=3020 all=303990 active=15670 piece=▁요소\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=145 size=3040 all=304485 active=16165 piece=지의\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=144 size=3060 all=305238 active=16918 piece=나도\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=143 size=3080 all=306014 active=17694 piece=▁말할\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=142 size=3100 all=306560 active=18240 piece=▁챙\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=142 min_freq=20\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=141 size=3120 all=307180 active=15937 piece=▁밥\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=141 size=3140 all=307974 active=16731 piece=▁여기서\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=140 size=3160 all=308622 active=17379 piece=▁마세요\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=139 size=3180 all=309290 active=18047 piece=▁재밋다\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=137 size=3200 all=309667 active=18424 piece=▁쪽\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=137 min_freq=20\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=136 size=3220 all=310185 active=15979 piece=BS\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=135 size=3240 all=311042 active=16836 piece=에만\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=134 size=3260 all=311562 active=17356 piece=가슴\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=133 size=3280 all=312550 active=18344 piece=▁끝날\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=132 size=3300 all=313007 active=18801 piece=애들\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=132 min_freq=19\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=131 size=3320 all=313809 active=16348 piece=▁시각\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=130 size=3340 all=314286 active=16825 piece=부족\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=129 size=3360 all=315137 active=17676 piece=ie\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=128 size=3380 all=315922 active=18461 piece=▁다니\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=127 size=3400 all=316417 active=18956 piece=▁인도\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=127 min_freq=19\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=126 size=3420 all=317120 active=16479 piece=겠어요\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=125 size=3440 all=317733 active=17092 piece=▁감동의\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=124 size=3460 all=318089 active=17448 piece=▁몰입감\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=123 size=3480 all=318467 active=17826 piece=배우가\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=122 size=3500 all=319168 active=18527 piece=▁많아\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=122 min_freq=19\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=121 size=3520 all=319553 active=16324 piece=▁뱀\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=121 size=3540 all=320310 active=17081 piece=▁대사가\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=120 size=3560 all=320840 active=17611 piece=▁관한\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=119 size=3580 all=321272 active=18043 piece=볼만\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=118 size=3600 all=322068 active=18839 piece=▁할까\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=118 min_freq=18\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=117 size=3620 all=322471 active=16501 piece=▁쩝\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=117 size=3640 all=323141 active=17171 piece=▁풍경\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=116 size=3660 all=323950 active=17980 piece=▁늘어\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=115 size=3680 all=324628 active=18658 piece=▁간다\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=115 size=3700 all=324881 active=18911 piece=▁지나치게\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=115 min_freq=18\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=114 size=3720 all=325438 active=16802 piece=▁기독교\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=113 size=3740 all=326063 active=17427 piece=▁다시는\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=112 size=3760 all=326675 active=18039 piece=임스\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=112 size=3780 all=327073 active=18437 piece=▁아름다움\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=111 size=3800 all=327602 active=18966 piece=▁남자의\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=111 min_freq=18\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=110 size=3820 all=328112 active=16884 piece=▁자살\n",
      "bpe_model_t"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 333295 Mar 23 06:53 korean_spm.model\r\n",
      "-rw-r--r-- 1 root root  82501 Mar 23 06:53 korean_spm.vocab\r\n"
     ]
    }
   ],
   "source": [
    "temp_file = os.getenv('HOME') + '/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp'\n",
    "\n",
    "vocab_size = 6000\n",
    "\n",
    "with open(temp_file, 'w') as f:\n",
    "    for row in filtered_corpus: # 이전 스텝에서 정제했던 corpus 활용\n",
    "        f.write(str(row) + '\\n')\n",
    "        \n",
    "spm.SentencePieceTrainer.Train('--input={} --model_prefix=korean_spm --vocab_size={} --model_type=bpe'.format(temp_file, vocab_size))\n",
    "\n",
    "# 위 Train에서 --model_type = 'unigram'이 디폴트 적용되어 있다.\n",
    "# --model_type = 'bpe' 로 옵션을 주어 변경할 수 있다.\n",
    "\n",
    "!ls -l korean_spm*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5f15742f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "s = spm.SentencePieceProcessor()\n",
    "s.Load('korean_spm.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "37af8272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁아', '버', '지가', '방', '에', '들어', '가', '신', '다', '.']\n"
     ]
    }
   ],
   "source": [
    "# SentencePiece를 활용한 sentence -> encoded pieces\n",
    "print(s.SampleEncodeAsPieces('아버지가방에들어가신다.', 1, 0.0))\n",
    "# 문자열에 대해 토크나이즈"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47288aa2",
   "metadata": {},
   "source": [
    "model_type=unigram 일 때와 토큰화된 모양이 다르다!\n",
    "\n",
    "### 1-2. Tokenizer 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "436e94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpe_tokenize(s, corpus):\n",
    "    \n",
    "    tensor = []\n",
    "    \n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen)) # 아이디로 문장 토큰화된 값 추가\n",
    "        \n",
    "    with open(\"./korean_spm.vocab\", 'r') as f:\n",
    "        vocab = f.readlines()\n",
    "        \n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "    \n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "        \n",
    "        word_index.update({word:idx})\n",
    "        index_word.update({idx:word})\n",
    "        \n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=100)\n",
    "    \n",
    "    return tensor, word_index, index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aa49f9",
   "metadata": {},
   "source": [
    "### 1-3. 데이터 로더 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e9cfb8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_data, test_data):\n",
    "    \n",
    "    # 토큰화 및 불용어 제거\n",
    "    X_train, word_index, index_word = bpe_tokenize(s, list(train_data['document']))\n",
    "    \n",
    "    X_test, _, _ = bpe_tokenize(s, list(test_data['document']))\n",
    "    \n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_index, index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "385c9a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, word_index, index_word = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19c036b",
   "metadata": {},
   "source": [
    "### 1-4. 모델 및 validation set 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8c656914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 16)          96000     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 96,881\n",
      "Trainable params: 96,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# bpe_tokenize를 이용한 모델\n",
    "vocab_size = 6000\n",
    "word_vector_dim = 16\n",
    "\n",
    "model_sp = tf.keras.Sequential()\n",
    "model_sp.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model_sp.add(tf.keras.layers.LSTM(8))\n",
    "model_sp.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model_sp.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_sp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cbdefa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116182, 100)\n",
      "(116182,)\n",
      "(30000, 100)\n"
     ]
    }
   ],
   "source": [
    "# validation set 구성\n",
    "x_val = X_train[:30000]\n",
    "y_val = y_train[:30000]\n",
    "\n",
    "# 나머지\n",
    "partial_x_train = X_train[30000:]\n",
    "partial_y_train = y_train[30000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6bc49a",
   "metadata": {},
   "source": [
    "### 1-5. 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a2522ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "454/454 [==============================] - 5s 8ms/step - loss: 0.6932 - accuracy: 0.4989 - val_loss: 0.6932 - val_accuracy: 0.4976\n",
      "Epoch 2/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6934 - val_accuracy: 0.4978\n",
      "Epoch 3/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6931 - val_accuracy: 0.5021\n",
      "Epoch 4/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.6932 - accuracy: 0.5002 - val_loss: 0.6931 - val_accuracy: 0.5021\n",
      "Epoch 5/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.6931 - accuracy: 0.5011 - val_loss: 0.6932 - val_accuracy: 0.4982\n",
      "Epoch 6/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.6924 - accuracy: 0.5056 - val_loss: 0.6835 - val_accuracy: 0.5017\n",
      "Epoch 7/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.5724 - accuracy: 0.7241 - val_loss: 0.5819 - val_accuracy: 0.6959\n",
      "Epoch 8/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.5745 - accuracy: 0.7026 - val_loss: 0.5673 - val_accuracy: 0.7257\n",
      "Epoch 9/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.5592 - accuracy: 0.7203 - val_loss: 0.5349 - val_accuracy: 0.7518\n",
      "Epoch 10/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.5114 - accuracy: 0.7751 - val_loss: 0.5019 - val_accuracy: 0.7889\n",
      "Epoch 11/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.4681 - accuracy: 0.8041 - val_loss: 0.4539 - val_accuracy: 0.8082\n",
      "Epoch 12/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.4105 - accuracy: 0.8299 - val_loss: 0.4091 - val_accuracy: 0.8246\n",
      "Epoch 13/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.3729 - accuracy: 0.8468 - val_loss: 0.3871 - val_accuracy: 0.8360\n",
      "Epoch 14/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.3492 - accuracy: 0.8582 - val_loss: 0.3729 - val_accuracy: 0.8414\n",
      "Epoch 15/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.3335 - accuracy: 0.8652 - val_loss: 0.3632 - val_accuracy: 0.8466\n",
      "Epoch 16/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.3232 - accuracy: 0.8693 - val_loss: 0.3607 - val_accuracy: 0.8461\n",
      "Epoch 17/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.3152 - accuracy: 0.8733 - val_loss: 0.3957 - val_accuracy: 0.8377\n",
      "Epoch 18/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.3079 - accuracy: 0.8765 - val_loss: 0.3571 - val_accuracy: 0.8500\n",
      "Epoch 19/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.2984 - accuracy: 0.8806 - val_loss: 0.3568 - val_accuracy: 0.8499\n",
      "Epoch 20/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.2899 - accuracy: 0.8846 - val_loss: 0.3562 - val_accuracy: 0.8485\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "model_sp.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "history = model_sp.fit(partial_x_train,\n",
    "                      partial_y_train,\n",
    "                      epochs=epochs,\n",
    "                      batch_size = 256,\n",
    "                      validation_data=(x_val, y_val),\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216debbe",
   "metadata": {},
   "source": [
    "### 1-6. 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b74b60ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 4s - loss: 0.3668 - accuracy: 0.8434\n",
      "-----<model_type=bpe 를 사용한 모델>-----: \n",
      " [0.36681124567985535, 0.8434200882911682]\n"
     ]
    }
   ],
   "source": [
    "results_sp = model_sp.evaluate(X_test, y_test, verbose=2)\n",
    "print('-----<model_type=bpe 를 사용한 모델>-----: \\n', results_sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9192f387",
   "metadata": {},
   "source": [
    "SentencePiece 모델을 학습하고 예시문장을 인코딩해봤는데, 사람의 눈으로 보기에는 단어가 띄어쓰기 형태가 model_type=unigram일 때에 비해 이해하기 어려웠다.   \n",
    "하지만 모델을 돌려보니 성능은 훨씬 좋게 나온다. \n",
    "\n",
    "**bpe**가 기본적으로 연속으로 많이 등장한 글자의 쌍을 찾아서 하나의 글자로 병합하는 방식이다보니 좋은 성능이 나온 것 같다.  \n",
    "반면 **unigram**의 경우 현재 단어의 확률만을 고려하기 때문에 깔끔하게 정돈된 글이 아닌 리뷰를 다루는 데에 있어서 성능이 그렇게 좋게 나오지 못 한 것 같다.\n",
    "- https://blog.floydhub.com/tokenization-nlp/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470e1c2d",
   "metadata": {},
   "source": [
    "***\n",
    "## 2. KoNLPy 형태소 분석기를 사용하여 모델 학습\n",
    "\n",
    "### 2-1. 데이터로더 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "5a386ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = Okt()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "num_words = 10000\n",
    "\n",
    "def load_data(train_data, test_data, num_words=num_words):\n",
    "    # 중복 및 결측치 제거\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how='any')\n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how='any')\n",
    "    \n",
    "    # 토큰화 및 불용어 제거\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_x = tokenizer.morphs(sentence) #형태소토큰화\n",
    "        temp_x = [word for word in temp_x if not word in stopwords]\n",
    "        X_train.append(temp_x)\n",
    "        \n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_x = tokenizer.morphs(sentence)\n",
    "        temp_x = [word for word in temp_x if not word in stopwords]\n",
    "        X_test.append(temp_x)\n",
    "    \n",
    "    # 사전 구성 \n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)\n",
    "    vocab = ['','','',''] + [key for key,_ in counter]\n",
    "    \n",
    "    word_to_index = {word: index for index,word in enumerate(vocab)}\n",
    "    \n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index[''] for word in wordlist]\n",
    "    \n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "    \n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "cc73823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "6731902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index: word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "39a44648",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {k:(v+3) for k, v in word_to_index.items()}\n",
    "\n",
    "#처음 몇 개 인덱스는 사전에 정의되어 있다.\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2 \n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word = {index: word for word,index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47531e2",
   "metadata": {},
   "source": [
    "### 2-2. 모델 구성을 위한 데이터 가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "ff3bf442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146182, 100)\n"
     ]
    }
   ],
   "source": [
    "#패딩 추가\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                      value=word_to_index[\"<PAD>\"],\n",
    "                                                      padding='pre',\n",
    "                                                      maxlen = 100)\n",
    "\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                     value=word_to_index[\"<PAD>\"],\n",
    "                                                     padding = 'pre',\n",
    "                                                     maxlen=100)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705c39f2",
   "metadata": {},
   "source": [
    "### 2-3. 모델 구성 및 validation set 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "2e29312b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, None, 16)          96000     \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 96,881\n",
      "Trainable params: 96,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 6000\n",
    "word_vector_dim = 16 #워드벡터의 차원수 \n",
    "\n",
    "#모델 설계 \n",
    "model_ko = tf.keras.Sequential()\n",
    "model_ko.add(tf.keras.layers.Embedding(vocab_size,word_vector_dim, input_shape=(None, )))\n",
    "model_ko.add(tf.keras.layers.LSTM(8))\n",
    "model_ko.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model_ko.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_ko.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "cbf2b1c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116182, 100)\n",
      "(116182,)\n",
      "(30000, 100)\n"
     ]
    }
   ],
   "source": [
    "# validation set 구성\n",
    "x_val = X_train[:30000]\n",
    "y_val = y_train[:30000]\n",
    "\n",
    "# 나머지\n",
    "partial_x_train = X_train[30000:]\n",
    "partial_y_train = y_train[30000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021ae092",
   "metadata": {},
   "source": [
    "### 2-4. 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "e0d0380b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "454/454 [==============================] - 7s 9ms/step - loss: 0.4679 - accuracy: 0.7845 - val_loss: 0.3613 - val_accuracy: 0.8404\n",
      "Epoch 2/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.3469 - accuracy: 0.8484 - val_loss: 0.3524 - val_accuracy: 0.8419\n",
      "Epoch 3/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.3300 - accuracy: 0.8557 - val_loss: 0.3495 - val_accuracy: 0.8434\n",
      "Epoch 4/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.3184 - accuracy: 0.8613 - val_loss: 0.3485 - val_accuracy: 0.8447\n",
      "Epoch 5/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.3075 - accuracy: 0.8662 - val_loss: 0.3513 - val_accuracy: 0.8436\n",
      "Epoch 6/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.2990 - accuracy: 0.8713 - val_loss: 0.3559 - val_accuracy: 0.8432\n",
      "Epoch 7/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.2904 - accuracy: 0.8747 - val_loss: 0.3620 - val_accuracy: 0.8408\n",
      "Epoch 8/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.2833 - accuracy: 0.8787 - val_loss: 0.3639 - val_accuracy: 0.8419\n",
      "Epoch 9/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.2768 - accuracy: 0.8816 - val_loss: 0.3710 - val_accuracy: 0.8397\n",
      "Epoch 10/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.2703 - accuracy: 0.8845 - val_loss: 0.3762 - val_accuracy: 0.8390\n",
      "Epoch 11/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.2640 - accuracy: 0.8877 - val_loss: 0.3859 - val_accuracy: 0.8394\n",
      "Epoch 12/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.2575 - accuracy: 0.8903 - val_loss: 0.3823 - val_accuracy: 0.8397\n",
      "Epoch 13/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.2512 - accuracy: 0.8938 - val_loss: 0.4010 - val_accuracy: 0.8360\n",
      "Epoch 14/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.2446 - accuracy: 0.8970 - val_loss: 0.3989 - val_accuracy: 0.8363\n",
      "Epoch 15/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.2376 - accuracy: 0.9004 - val_loss: 0.4262 - val_accuracy: 0.8350\n",
      "Epoch 16/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.2314 - accuracy: 0.9028 - val_loss: 0.4122 - val_accuracy: 0.8347\n",
      "Epoch 17/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.2243 - accuracy: 0.9061 - val_loss: 0.4296 - val_accuracy: 0.8334\n",
      "Epoch 18/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.2168 - accuracy: 0.9095 - val_loss: 0.4555 - val_accuracy: 0.8327\n",
      "Epoch 19/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.2108 - accuracy: 0.9123 - val_loss: 0.4571 - val_accuracy: 0.8304\n",
      "Epoch 20/20\n",
      "454/454 [==============================] - 3s 7ms/step - loss: 0.2047 - accuracy: 0.9153 - val_loss: 0.4704 - val_accuracy: 0.8318\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "model_ko.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "history = model_ko.fit(partial_x_train,\n",
    "                      partial_y_train,\n",
    "                      epochs=epochs,\n",
    "                      batch_size = 256,\n",
    "                      validation_data=(x_val, y_val),\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cfc868",
   "metadata": {},
   "source": [
    "### 2-5. 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "963a4555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 4s - loss: 0.4836 - accuracy: 0.8259\n",
      "-----<KoNLPy를 사용한 모델>-----: \n",
      " [0.48361286520957947, 0.8258640766143799]\n"
     ]
    }
   ],
   "source": [
    "results_ko = model_ko.evaluate(X_test, y_test, verbose=2)\n",
    "print('-----<KoNLPy를 사용한 모델>-----: \\n', results_ko)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167c6a91",
   "metadata": {},
   "source": [
    "학습데이터는 정확도가 91 까지 올라간 데 비해 검증데이터의 정확도는 82 정도이다.   \n",
    "***\n",
    "\n",
    "\n",
    "예전부터 한글과 영어를 같이 분석하는 방식이 궁금했는데 이번에 SentencePiece를 통해 해결책을 찾은 것 같다.\n",
    "\n",
    "프로젝트를 진행하면서 SentencePiece를 어떻게 어디서부터 활용해야할지 고민이었는데, 하다보니 방법이 나왔다. 맞는지는 모르겠다. 딥러닝 모델도 오랜만에 보니 잘 모르겠다.  \n",
    "\n",
    "우선 데이터를 받아와서 결측치와 중복값만 처리를 해주었다.  \n",
    "KoNLPy에서는 토큰화와 더불어서 불용어도 처리하고 여러가지 처리가 들어갔는데, sentencepiece는 불용어는 처리하지 않았다.  \n",
    "\n",
    "SentencePiece 모델에도 model_type이 여러가지 있는데, 그 중에 unigram과 bpe를 적용시켜 모델을 학습시켜보았다.  \n",
    "\n",
    "먼저 **unigram**이 적용된 spm을 단어사전 개수 8000개로 모델을 돌려보았다. 학습데이터에 대한 정확도가 계속 50% 정도에서 머물러 있어서 잘못 처리한 줄 알았다.  \n",
    "단어사전이 너무 많나 싶어 **단어개수를 6000**개로 바꾸고 padding을 하는 과정에서 **max_len도 100**으로 설정을 해주었다. (원랜 140정도였고, 이게 데이터에서 가장 긴 문장길이이다.)  \n",
    "다시 돌려보니 테스트 정확도가 **66%** 까지 꽤 올라갔지만 만족스럽진 않았다.\n",
    "\n",
    "다음으로 **model_type = bpe**로 바꿔 sentencepiece를 학습시키고 데이터를 토큰화해서 딥러닝 모델을 학습시켜봤다. 위에서 단어개수 6000개가 성능이 괜찮았기에 계속 이걸로 학습시켰고, 테스트 **정확도는 84%** 에 loss는 0.36 정도로 나름 괜찮은 결과가 나왔다.\n",
    "\n",
    "마지막으로 **KoNLPy**를 활용해서 같은 조건의 데이터(단어사전개수 6000개, maxlen=100)를 학습시켜봤다. 학습데이터의 정확도가 91% 까지 올라가길래 혹시 불용어처리를 해서 성능이 좋은 건가 싶었다. 하지만 테스트데이터의 **정확도가 82%** 정도 나와서 과적합이 의심된다.  \n",
    "\n",
    "결과적으로 가장 좋은 성능을 보인 모델은 **SentencePiece**를 적용시킨 모델이었고 그 중에서도 model_type이 **bpe** 일 때이다.   \n",
    "unigram과 bpe가 어떻게 다르길래 성능차이가 이렇게 심하게 나나 싶어 찾아본 [블로그](https://blog.floydhub.com/tokenization-nlp/). 또 읽어보자.   \n",
    "\n",
    "간단히 정리하면 **bpe**는 기본적으로 연속으로 많이 등장한 글자의 쌍을 찾아서 하나의 글자로 병합하는 방식이다보니 좋은 성능이 나온 반면 **unigram**의 경우 현재 단어의 확률만을 고려하기 때문에 깔끔하게 정돈된 글이 아닌 리뷰를 다루는 데에 있어서 성능이 그렇게 좋게 나오지 못 한 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66053b17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
